{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97194c3",
   "metadata": {},
   "source": [
    "Auto-install Missing Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a817310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (only if not already installed)\n",
    "!pip install torch torchvision torchaudio torchsummary matplotlib scikit-learn --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b1d08",
   "metadata": {},
   "source": [
    "Imports & Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beae83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd439c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0599a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
      "Train samples: 3272\n",
      "Test samples: 786\n"
     ]
    }
   ],
   "source": [
    "# Path to dataset\n",
    "data_dir = \"AxialDataset\"  # adjust path if needed\n",
    "\n",
    "# Image transforms (force grayscale → resize → normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),   # ✅ grayscale\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(f\"{data_dir}/Training\", transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(f\"{data_dir}/Testing\",  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "classes = train_dataset.classes\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Test samples:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8b048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: tensor([0.0005, 0.0017, 0.0018, 0.0047], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Counts from your dataset\n",
    "class_counts = [1893, 602, 562, 215]  # [notumor, glioma, meningioma, pituitary]\n",
    "\n",
    "# Inverse frequency\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "class_weights = class_weights.to(device)\n",
    "print(\"Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e4cb6",
   "metadata": {},
   "source": [
    "Visualize a Few Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0237541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adith\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adith\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify input layer (grayscale → 1 channel)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Modify output layer (num_classes = 4)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(classes))\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6884aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify input layer (grayscale → 1 channel)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Modify output layer (num_classes = 4)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(classes))\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb95646",
   "metadata": {},
   "source": [
    "Define Model (ResNet18 → 4 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1224eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    history = {\"train_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = correct / total\n",
    "        history[\"train_loss\"].append(running_loss / len(train_loader))\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {running_loss/len(train_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2a155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_dir = \"AxialDataset\"  # <-- change if your dataset is elsewhere\n",
    "\n",
    "# Train augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(f\"{data_dir}/Training\", transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder(f\"{data_dir}/Testing\", transform=test_transform)\n",
    "\n",
    "# Split train into train+val (80/20 split)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# ✅ DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Class names\n",
    "classes = train_dataset.classes\n",
    "print(\"Classes:\", classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ff67a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Loss function (CrossEntropy for classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (Adam is good, you can try SGD too)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62ba1e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.4488 | Val Acc: 0.8504\n",
      "Epoch 2/10 | Train Loss: 0.2400 | Val Acc: 0.7557\n",
      "Epoch 3/10 | Train Loss: 0.1771 | Val Acc: 0.8656\n",
      "Epoch 4/10 | Train Loss: 0.1462 | Val Acc: 0.8962\n",
      "Epoch 5/10 | Train Loss: 0.1088 | Val Acc: 0.8702\n",
      "Epoch 6/10 | Train Loss: 0.0846 | Val Acc: 0.9618\n",
      "Epoch 7/10 | Train Loss: 0.0762 | Val Acc: 0.9466\n",
      "Epoch 8/10 | Train Loss: 0.0957 | Val Acc: 0.9374\n",
      "Epoch 9/10 | Train Loss: 0.0696 | Val Acc: 0.9725\n",
      "Epoch 10/10 | Train Loss: 0.0452 | Val Acc: 0.9756\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "507177c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as brain_tumor_model_v2.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"brain_tumor_model_v2.pth\")\n",
    "print(\"✅ Model saved as brain_tumor_model_v2.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab2aab01",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, Label, Button\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# ======================\n",
    "# Load Trained Model\n",
    "# ======================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define model architecture (ResNet18 modified for grayscale)\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)  # 4 classes\n",
    "model.load_state_dict(torch.load(\"brain_tumor_model_v2.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Class labels\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# ======================\n",
    "# Image Transform\n",
    "# ======================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# ======================\n",
    "# Grad-CAM Implementation\n",
    "# ======================\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0].detach()\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate_heatmap(self, input_tensor, class_idx=None):\n",
    "        output = self.model(input_tensor)\n",
    "\n",
    "        if class_idx is None:\n",
    "            class_idx = torch.argmax(output)\n",
    "\n",
    "        # Backpropagate for target class\n",
    "        self.model.zero_grad()\n",
    "        output[0, class_idx].backward()\n",
    "\n",
    "        # Pool gradients\n",
    "        pooled_gradients = torch.mean(self.gradients, dim=[0, 2, 3])\n",
    "        activations = self.activations[0]\n",
    "\n",
    "        for i in range(len(pooled_gradients)):\n",
    "            activations[i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "        heatmap = torch.mean(activations, dim=0).cpu().numpy()\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        heatmap /= np.max(heatmap) if np.max(heatmap) != 0 else 1\n",
    "        return heatmap\n",
    "\n",
    "# Initialize Grad-CAM on the last conv layer of ResNet18\n",
    "grad_cam = GradCAM(model, model.layer4[1].conv2)\n",
    "\n",
    "# ======================\n",
    "# Prediction + Heatmap Function\n",
    "# ======================\n",
    "def predict_and_heatmap(img_path):\n",
    "    image = Image.open(img_path).convert(\"L\")  # grayscale\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    pred_class = classes[predicted.item()]\n",
    "\n",
    "    # Heatmap\n",
    "    heatmap = grad_cam.generate_heatmap(img_tensor, predicted.item())\n",
    "    heatmap = cv2.resize(heatmap, (image.size[0], image.size[1]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    img = np.array(image.convert(\"RGB\"))\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    return pred_class, image, Image.fromarray(superimposed_img)\n",
    "\n",
    "# ======================\n",
    "# Tkinter UI\n",
    "# ======================\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    if not file_path:\n",
    "        return\n",
    "\n",
    "    # Prediction + Heatmap\n",
    "    prediction, orig_img, heatmap_img = predict_and_heatmap(file_path)\n",
    "\n",
    "    # Display original image\n",
    "    img_resized = orig_img.resize((200, 200))\n",
    "    img_tk = ImageTk.PhotoImage(img_resized)\n",
    "    panel.config(image=img_tk)\n",
    "    panel.image = img_tk\n",
    "\n",
    "    # Display heatmap image\n",
    "    heatmap_resized = heatmap_img.resize((200, 200))\n",
    "    heatmap_tk = ImageTk.PhotoImage(heatmap_resized)\n",
    "    panel_heatmap.config(image=heatmap_tk)\n",
    "    panel_heatmap.image = heatmap_tk\n",
    "\n",
    "    # Display prediction\n",
    "    result_label.config(text=f\"Prediction: {prediction}\", font=(\"Arial\", 14, \"bold\"))\n",
    "\n",
    "# Create main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Brain Tumor Detection with Heatmap\")\n",
    "root.geometry(\"500x500\")\n",
    "\n",
    "# UI Elements\n",
    "btn = Button(root, text=\"Upload MRI Image\", command=upload_image, font=(\"Arial\", 12), bg=\"lightblue\")\n",
    "btn.pack(pady=10)\n",
    "\n",
    "frame = tk.Frame(root)\n",
    "frame.pack()\n",
    "\n",
    "panel = Label(frame)  # Original image\n",
    "panel.grid(row=0, column=0, padx=10)\n",
    "\n",
    "panel_heatmap = Label(frame)  # Heatmap\n",
    "panel_heatmap.grid(row=0, column=1, padx=10)\n",
    "\n",
    "result_label = Label(root, text=\"\", font=(\"Arial\", 14))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Run Tkinter loop\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
